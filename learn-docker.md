# Learning Docker

Source: [YouTube](https://www.youtube.com/watch?v=RqTEHSBrYFw)

<a href="https://www.youtube.com/watch?v=RqTEHSBrYFw" target="_blank">
 <img src="http://img.youtube.com/vi/RqTEHSBrYFw/mqdefault.jpg" alt="Watch the video" height="180" border="10" />
</a>

### So, What is Docker?
Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications. By taking advantage of Docker's methodologies for shipping, testing, and deploying code, you can significantly reduce the delay between writing code and running it in production.

### What is a Container?
- A way to package applications with all necessary dependencies and configuration.
- Portable artifact, easily shared and moved around.
- Makes development and deployment more efficient.

### Where do containers live?
- Container Repository
- Private Repositories
- Public Repository for Docker (AKA Docker Hub)

## Motivation for Containers
### Development
Before Docker: "To get the development environment set up install Postgres, MongoDB, and run these 5 scripts. Oh wait, You're on Windows? Also Change These Configurations."
After Docker: "Run `docker compose up`."

### Deployment
Before Docker: "To deploy the applicaton, provision a server running Ubuntu, run this Ansible playbook to install the dependencies and configure the system, then copy the deployment binary and run it with these options."
After Docker: "Run this container image with these options."

## Evolution of Virtualization
### Bare Metal
- Hellish Dependency Conflicts.
- Low utilization efficiency.
- Large blast radius (the changes/issues of one application can direcly impace the performance of other applications)
- Slow Start Up and Shut Down Speed (minutes).
- Very slow provisioning & decommissioning (Hours to Days).

### Virtual Machines
- No Dependency Conflicts.
- Better utilization efficiency.
- Small blast radius.
- Faster startup and shutdown (minutes).
- Faster provisioning & decommissioning (minutes) (Used in Cloud Computing).

### Containers
- No Dependency Conflicts.
- Even Better Utilization efficiency.
- Small blast radius.
- Even faster startup and shutdown (seconds).
- Even faster provisioning & decommissioning (seconds).
- Lightweight enough to use in development.

# Technology Overview
## Container Building Blocks
- Namespaces
- Control Groups
- Union Filesystem

### Namespaces
A Namespace wraps a global system resource in abstraction that makes it appear to the processes within the namespace that they have their own isolated instance of global resource.

### cgroups
A Linux kernel feature which allow processes to be organized into hierarchical groups whose usage of various types of resources can then be limited and monitored.

### Union Mount Filesystem (overlayfs)
Allows files and directories of seperate filesystems, known as branches, to be transparently overaid, forming a single coherent filesystem.

Contents of directories which have the same path within the merged branches will be seen together in a single merged directory, within the new virtual filesystem.

## Let's Run our First Container
```
docker run docker/whalesay cowsay "Hello Team!"
```
That was fun and easy!

Let's Now get into some more useful docker containers!
```
docker run --env POSTGRES_PASSWORD=thisispassword --publish 5432:5432 postgres:15.1-alpine
```
This will create a postgresql database server, with the password `thisispassword` and exposed at the port 5432. You can then connect to the postgres server at the port 5432 using the command `psql -U postgres -h 172.17.0.1 -p 5432`, The IP might be different in your case.

## Understanding Data within Containers
- If some data should be present every time a container image is run (e.g. dependency), It should be built into the image itself.
- If data generated by the Application hat needs to be persisted, A Volume should be used to store that outside of the ephemeral (tied to lifecycle of containes) container filesystem.

### Let's now get Containerizing
```
docker run --interactive --tty --rm ubuntu:22.04
```
This will give us an interactive session for the ubuntu container which will be created. The --rm argument specifies that whenever the container is stopped, remove all the files/data of that container.

#### Let's now make a container that stays
```
docker run --interactive --tty --name my-ubuntu-container ubuntu:22.04
```
This will give us an interactive terminal session for the ubuntu container which is just created but will also keep the container until and unless explicitly mentioned to remove.
This container will persist even after stopping the container and can be looked at using `docker ps -a`. And now that the container persists, Any dependencies which we installed inside this container will also stay.

This container can be later started by the `docker start my-ubuntu-container` command.
```
docker attach my-ubuntu-container
```
Can be then used to connect to a shell to this container.

But we wouldn't want to everytime install dependencies when we start a container, right? We would want that It should already be there in the container when we start a container. For this we can use:
```
docker build --tag my-ubuntu-image -<<EOF
FROM ubuntu:22.04
RUN apt update && apt install iputils-ping -y
EOF
```
And now a container can be run on top of this image using `docker run -it --rm my-ubuntu-image`. This will have the dependencies already installed in the new container and we won't have to go through the hassle of doing things over and over again.

### Mounting to Containers
```
docker volume create my-volume
```
This will create a new docker volume which can be mounted anywhere you'd like to mount it.

To create a container with the volume mounted into the container, we use: 

```
docker run --it --rm --mount source=my-volume,destination=/my-data/ ubuntu:22.04
```

By default the volume will be stores inside the `/var/lib/docker/volumes` directory.

```
docker run --it --rm --mount type=bind,source=$(pwd)/my-data,destination=/my-data ubuntu22:04
```

This another type of mount you can use if you need to work on the data, known as the bind mount. As the bind mount is located on the system, You have better visibility of the things happening in the mount directory if you're using bind mounts.

## Building Container Images
### Dockerfile
A text document that contains all the command a user could call on the command line to assemble an image.
You can also have a .dockerignore file which would tell docker to ignore certain files so we don't copy unnecessary files to the docker while building the image to save ourself from incompatibilities. 

It's good practice to put your dockerfile where your code is living.

### Dockerfile V01

``` Dockerfile
FROM ubuntu:22.04
RUN apt update && apt install git python3 python3-pip -y && mkdir /root/app
WORKDIR /root/app
RUN pip install fastapi uvicorn
COPY hello.py .
CMD ["uvicorn", "hello:app", "--host", "0.0.0.0", "--port", "8000"]
```
We built the image on top of the `ubuntu:22.04` image, ran `apt update` so that we could install `python3` and `python3-pip` packages for running our application. Also we made a directory to keep our application's code. A single file in this case. Set the work directory to `/root/app`. Then we ran `pip install fastapi uvicorn` to install the dependencies our app is dependent on. Copied the app to the working directory. And used the command to deploy our application.

And this might not be our best Dockerfile, so we will further look at how we can improve the Dockerfile so that it reduces deployment time and makes the process faster.

This is the first revision of the Dockerfile we made, We will see how to improve upon it when we make revisions.

The command we will be using to build this image will be:

```
docker build -t my-fastapi-app:01
```

And we can run the container using the command:

```
docker run -p 8000:8000 my-fastapi-app:01
```
This will create a new container from the docker image we built. The image is sized at 513 MB.

### Dockerfile V02
Let's now look at how we can make the Dockerfile better.

Let's try using the `python3.11.9-alpine3.19` image for the application, As it will come prepackaged with python3 and pip, we will just need to install the `fastapi` and `uvicorn` python modules.

So according to that, Our dockerfile will look something like this.

``` Dockerfile
FROM python:3.11.9-alpine3.19
RUN mkdir /root/app
WORKDIR /root/app
RUN pip install fastapi uvicorn
COPY hello.py .
EXPOSE 8000
CMD ["uvicorn", "hello:app", "--host", "0.0.0.0", "--port", "8000"]
```

We'll now use the same commands to build and run the image in a container with minor tweaks.

The command we will be using to build this image will be:

```
docker build -t my-fastapi-app:02
```
The 02 in the end will differenciate the two `my-fastapi-app` images and the text after the `:` is called the tag of the image.

Now you can execute `docker image ls` to list all the available dockers images so that you can see how different they are in their sizes.

The new image is of the size 82.5 MB. i.e. 6.2 times smaller than the first image we built.

So, this is how you can improve the Dockerfile to reduce image sizes, deployment time, etc.
